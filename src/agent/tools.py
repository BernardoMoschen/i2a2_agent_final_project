"""LangChain tool wrappers for fiscal document processing."""

import logging
from datetime import datetime
from typing import Any, Optional

from langchain.tools import BaseTool
from pydantic import BaseModel, Field

from src.database.db import DatabaseManager
from src.models import InvoiceModel, ValidationIssue
from src.tools.fiscal_validator import FiscalValidatorTool
from src.tools.xml_parser import XMLParserTool

logger = logging.getLogger(__name__)


class ParseXMLInput(BaseModel):
    """Input schema for XML parsing tool."""

    xml_content: str = Field(..., description="Raw XML content to parse")


class ParseXMLTool(BaseTool):
    """Tool for parsing Brazilian fiscal XML documents (NFe, NFCe, CTe, MDFe)."""

    name: str = "parse_fiscal_xml"
    description: str = """
    Parse Brazilian fiscal XML documents (NFe, NFCe, CTe, MDFe) into structured data.
    Input: raw XML string (can be full XML or just the key parts)
    Output: Formatted summary with issuer, recipient, items, totals, and taxes
    
    Use this tool when:
    - User uploads or pastes XML content
    - User asks to "parse", "process", or "analyze" a fiscal document
    - User mentions NFe, NFCe, CTe, or MDFe
    
    The tool automatically extracts:
    - Document type and key
    - Issuer (emitente) information
    - Recipient (destinat√°rio) information  
    - All items with prices and taxes
    - Total values and tax breakdown
    """
    args_schema: type[BaseModel] = ParseXMLInput

    def _run(self, xml_content: str) -> str:
        """Parse XML and return structured invoice data."""
        try:
            parser = XMLParserTool()
            invoice = parser.parse(xml_content)

            # Return a human-friendly summary
            result = f"""
‚úÖ Documento fiscal parseado com sucesso!

üìÑ Tipo: {invoice.document_type}
üîë Chave de Acesso: {invoice.document_key}
üìã N√∫mero: {invoice.document_number} / S√©rie: {invoice.series}
üìÖ Data de Emiss√£o: {invoice.issue_date.strftime('%d/%m/%Y %H:%M:%S')}

üë§ Emitente: {invoice.issuer_name}
   CNPJ: {invoice.issuer_cnpj}

üë• Destinat√°rio: {invoice.recipient_name or 'N√£o especificado'}
   {f"CNPJ/CPF: {invoice.recipient_cnpj_cpf}" if invoice.recipient_cnpj_cpf else ""}

üí∞ Valores:
   Produtos: R$ {invoice.total_products:,.2f}
   Impostos: R$ {invoice.total_taxes:,.2f}
   Total da NF: R$ {invoice.total_invoice:,.2f}

üì¶ Itens: {len(invoice.items)}
"""
            # Add item details
            for item in invoice.items[:5]:  # Show first 5 items
                result += f"\n   {item.item_number}. {item.description} - {item.quantity} {item.unit} √ó R$ {item.unit_price:,.2f} = R$ {item.total_price:,.2f}"

            if len(invoice.items) > 5:
                result += f"\n   ... e mais {len(invoice.items) - 5} itens"

            return result

        except Exception as e:
            return f"‚ùå Erro ao parsear XML: {str(e)}"

    async def _arun(self, xml_content: str) -> str:
        """Async version."""
        return self._run(xml_content)


class ValidateInvoiceInput(BaseModel):
    """Input schema for validation tool."""

    xml_content: str = Field(..., description="Raw XML content to validate")


class ValidateInvoiceTool(BaseTool):
    """Tool for validating Brazilian fiscal documents against fiscal rules."""

    name: str = "validate_fiscal_document"
    description: str = """
    Validate a Brazilian fiscal document (NFe, NFCe) against fiscal rules.
    Checks: document key format, CNPJ, totals, item calculations, CFOP, NCM, dates.
    Input: raw XML string
    Output: List of validation issues with severity (ERROR, WARNING, INFO) and suggestions.
    Use this after parsing to check document compliance.
    """
    args_schema: type[BaseModel] = ValidateInvoiceInput

    def _run(self, xml_content: str) -> str:
        """Validate document and return issues."""
        try:
            # First parse
            parser = XMLParserTool()
            invoice = parser.parse(xml_content)

            # Then validate
            validator = FiscalValidatorTool()
            issues = validator.validate(invoice)

            if not issues:
                return "‚úÖ Documento v√°lido! Nenhum problema encontrado."

            # Format issues
            result = f"üìã Valida√ß√£o conclu√≠da: {len(issues)} problema(s) encontrado(s)\n\n"

            errors = [i for i in issues if i.severity == "error"]
            warnings = [i for i in issues if i.severity == "warning"]
            infos = [i for i in issues if i.severity == "info"]

            if errors:
                result += "‚ùå ERROS:\n"
                for issue in errors:
                    result += f"  ‚Ä¢ {issue.code}: {issue.message}\n"
                    if issue.field:
                        result += f"    Campo: {issue.field}\n"
                    if issue.suggestion:
                        result += f"    Sugest√£o: {issue.suggestion}\n"
                result += "\n"

            if warnings:
                result += "‚ö†Ô∏è  AVISOS:\n"
                for issue in warnings:
                    result += f"  ‚Ä¢ {issue.code}: {issue.message}\n"
                    if issue.field:
                        result += f"    Campo: {issue.field}\n"
                    if issue.suggestion:
                        result += f"    Sugest√£o: {issue.suggestion}\n"
                result += "\n"

            if infos:
                result += "‚ÑπÔ∏è  INFORMA√á√ïES:\n"
                for issue in infos:
                    result += f"  ‚Ä¢ {issue.code}: {issue.message}\n"
                    if issue.suggestion:
                        result += f"    Sugest√£o: {issue.suggestion}\n"
                result += "\n"

            # Summary
            result += f"üìä Resumo: {len(errors)} erro(s), {len(warnings)} aviso(s), {len(infos)} info(s)\n"

            if errors:
                result += "\n‚õî Documento possui ERROS e n√£o deve ser processado!"
            elif warnings:
                result += "\n‚ö†Ô∏è  Documento pode ser processado, mas com aten√ß√£o aos avisos."
            else:
                result += "\n‚úÖ Documento v√°lido e pronto para processamento!"

            return result

        except Exception as e:
            return f"‚ùå Erro ao validar documento: {str(e)}"

    async def _arun(self, xml_content: str) -> str:
        """Async version."""
        return self._run(xml_content)


class AnswerQuestionInput(BaseModel):
    """Input schema for general questions."""

    question: str = Field(..., description="User's question about fiscal documents")


class FiscalKnowledgeTool(BaseTool):
    """Tool for answering general questions about Brazilian fiscal documents."""

    name: str = "fiscal_knowledge"
    description: str = """
    Answer general questions about Brazilian fiscal documents, tax rules, and processes.
    Use this for questions about:
    - What is NFe, NFCe, CTe, MDFe
    - Tax types (ICMS, IPI, PIS, COFINS, ISS)
    - CFOP codes and their meanings
    - NCM classification
    - Fiscal document requirements
    Do NOT use this for parsing or validating specific documents.
    """
    args_schema: type[BaseModel] = AnswerQuestionInput

    def _run(self, question: str) -> str:
        """Provide general fiscal knowledge."""
        # This would ideally use a knowledge base or RAG
        # For now, return a helpful message
        return """
Sou um agente especializado em documentos fiscais brasileiros. Posso ajudar com:

üìÑ **Tipos de Documentos:**
- NFe: Nota Fiscal Eletr√¥nica (vendas em geral)
- NFCe: Nota Fiscal de Consumidor Eletr√¥nica (varejo)
- CTe: Conhecimento de Transporte Eletr√¥nico
- MDFe: Manifesto Eletr√¥nico de Documentos Fiscais

üí∞ **Impostos:**
- ICMS: Imposto sobre Circula√ß√£o de Mercadorias e Servi√ßos
- IPI: Imposto sobre Produtos Industrializados
- PIS/COFINS: Contribui√ß√µes sociais
- ISS: Imposto sobre Servi√ßos

üî¢ **C√≥digos:**
- CFOP: C√≥digo Fiscal de Opera√ß√µes (ex: 5102 = venda dentro do estado)
- NCM: Nomenclatura Comum do Mercosul (classifica√ß√£o de produtos)

Para perguntas espec√≠ficas, forne√ßa mais detalhes ou um documento XML para an√°lise!
"""

    async def _arun(self, question: str) -> str:
        """Async version."""
        return self._run(question)


class SearchInvoicesInput(BaseModel):
    """Input schema for searching invoices in database."""

    document_type: Optional[str] = Field(None, description="Filter by document type: NFe, NFCe, CTe, or MDFe")
    operation_type: Optional[str] = Field(None, description="Filter by operation type: purchase (compra), sale (venda), transfer (transfer√™ncia), or return (devolu√ß√£o)")
    issuer_cnpj: Optional[str] = Field(None, description="Filter by issuer CNPJ (14 digits)")
    days_back: Optional[int] = Field(9999, description="Search last N days. Default is 9999 to search ALL documents ever processed. ALWAYS use 9999 when user asks about counts, years, or 'all' documents.")


class DatabaseSearchTool(BaseTool):
    """Tool for searching invoices in the SQLite database."""

    name: str = "search_invoices_database"
    description: str = """
    Search for fiscal documents stored in the database with flexible filters.
    
    üö® CRITICAL: When user asks about counting or listing documents, you MUST use days_back=9999!
    
    ‚ö†Ô∏è MANDATORY RULES (YOU MUST FOLLOW):
    1. ANY question with "quantas", "quantos", "how many", "count", "total" ‚Üí days_back=9999
    2. ANY question about a specific YEAR (2024, 2023, etc.) ‚Üí days_back=9999
    3. ANY question with "todas", "todos", "all", "list", "mostre", "traga" ‚Üí days_back=9999
    4. ANY question about specific dates ‚Üí days_back=9999
    5. Documents in database may be from any year ‚Üí ALWAYS use days_back=9999
    
    ‚úÖ CORRECT USAGE EXAMPLES:
    - "Quantas notas de compra?" ‚Üí {"operation_type": "purchase", "days_back": 9999}
    - "Documentos de 2024?" ‚Üí {"days_back": 9999}
    - "Me traga 5 XMLs de 2024" ‚Üí {"days_back": 9999}
    - "H√° documento na data 2024-01-19?" ‚Üí {"days_back": 9999}
    - "Total de documentos" ‚Üí {"days_back": 9999}
    
    ‚ùå WRONG - DO NOT DO THIS:
    - Using days_back=30 or days_back=365 for ANY query
    - Using "limit" parameter (not supported - tool returns up to 100 results)
    
    OPERATION TYPE MAPPING:
    - "compra", "purchase", "entrada" ‚Üí operation_type="purchase"
    - "venda", "sale", "sa√≠da" ‚Üí operation_type="sale"
    - "transfer√™ncia", "transfer" ‚Üí operation_type="transfer"
    - "devolu√ß√£o", "return" ‚Üí operation_type="return"
    
    Returns: Count and detailed list of invoices with operation type, issuer, date, total value
    """
    args_schema: type[BaseModel] = SearchInvoicesInput

    def _run(
        self,
        document_type: Optional[str] = None,
        operation_type: Optional[str] = None,
        issuer_cnpj: Optional[str] = None,
        days_back: int = 9999,
    ) -> str:
        """Search invoices in database."""
        try:
            logger.info(f"DatabaseSearchTool called with: document_type={document_type}, operation_type={operation_type}, issuer_cnpj={issuer_cnpj}, days_back={days_back}")
            
            # Create database connection (no state stored)
            db = DatabaseManager("sqlite:///fiscal_documents.db")
            
            # Search database with all filters
            invoices = db.search_invoices(
                document_type=document_type,
                operation_type=operation_type,
                issuer_cnpj=issuer_cnpj,
                days_back=days_back,
                limit=100,
            )
            
            logger.info(f"DatabaseSearchTool found {len(invoices)} documents")
            
            if not invoices:
                filter_desc = []
                if document_type:
                    filter_desc.append(f"Tipo: {document_type}")
                if operation_type:
                    op_label = {"purchase": "Compra", "sale": "Venda", "transfer": "Transfer√™ncia", "return": "Devolu√ß√£o"}.get(operation_type, operation_type)
                    filter_desc.append(f"Opera√ß√£o: {op_label}")
                if issuer_cnpj:
                    filter_desc.append(f"Emitente: {issuer_cnpj}")
                filter_desc.append(f"Per√≠odo: √öltimos {days_back} dias")
                
                return f"""
üîç Nenhum documento encontrado com os filtros:
{chr(10).join(f'- {f}' for f in filter_desc)}

üí° Verifique se h√° documentos cadastrados no banco de dados.
Para ver TODOS os documentos sem filtros, use days_back=9999 sem outros par√¢metros.
"""
            
            # Count by operation type
            op_counts = {}
            for inv in invoices:
                op = inv.operation_type or "not_classified"
                op_counts[op] = op_counts.get(op, 0) + 1
            
            # Format results
            result = f"""
üìä **Encontrados {len(invoices)} documento(s):**

"""
            
            # Show operation type breakdown if filtered or multiple types exist
            if len(op_counts) > 1 or operation_type:
                result += "**Por Tipo de Opera√ß√£o:**\n"
                op_labels = {
                    "purchase": "üì• Compras",
                    "sale": "üì§ Vendas", 
                    "transfer": "üîÑ Transfer√™ncias",
                    "return": "‚Ü©Ô∏è Devolu√ß√µes",
                    "not_classified": "‚ùì N√£o classificado"
                }
                for op, count in sorted(op_counts.items()):
                    label = op_labels.get(op, op)
                    result += f"- {label}: {count}\n"
                result += "\n"
            
            # Show first 15 documents
            for inv in invoices[:15]:
                op_emoji = {
                    "purchase": "üì•",
                    "sale": "üì§",
                    "transfer": "üîÑ",
                    "return": "‚Ü©Ô∏è"
                }.get(inv.operation_type, "üìÑ")
                
                op_label = {
                    "purchase": "Compra",
                    "sale": "Venda",
                    "transfer": "Transfer",
                    "return": "Devolu√ß√£o"
                }.get(inv.operation_type, "N/A") if inv.operation_type else "N/A"
                
                result += f"""
{op_emoji} **{inv.document_type}** - {inv.document_number}/{inv.series} | {op_label}
   üè¢ Emitente: {inv.issuer_name[:40]}
   üìÖ Data: {inv.issue_date.strftime('%d/%m/%Y')}
   üí∞ Valor: R$ {inv.total_invoice:,.2f}

"""
            
            if len(invoices) > 15:
                result += f"\n_... e mais {len(invoices) - 15} documento(s)_\n\n"
            
            # Add statistics
            total_value = sum(inv.total_invoice for inv in invoices)
            result += f"""
**Resumo Final:**
- üìÑ Total de documentos: {len(invoices)}
- üí∞ Valor total: R$ {total_value:,.2f}
"""
            
            return result
            
        except Exception as e:
            return f"‚ùå Erro ao buscar no banco de dados: {str(e)}"

    async def _arun(
        self,
        document_type: Optional[str] = None,
        operation_type: Optional[str] = None,
        issuer_cnpj: Optional[str] = None,
        days_back: int = 3650,
    ) -> str:
        """Async version."""
        return self._run(document_type, operation_type, issuer_cnpj, days_back)


class GetStatisticsInput(BaseModel):
    """Input schema for getting database statistics."""

    pass  # No input needed


class DatabaseStatsTool(BaseTool):
    """Tool for getting database statistics."""

    name: str = "get_database_statistics"
    description: str = """
    Get statistics about processed fiscal documents in the database.
    
    Use this when user asks:
    - "Quantos documentos temos?"
    - "Estat√≠sticas do banco"
    - "Resumo dos documentos processados"
    
    Returns: Total documents, items, issues, and breakdown by document type
    """
    args_schema: type[BaseModel] = GetStatisticsInput

    def _run(self) -> str:
        """Get database statistics."""
        try:
            # Create database connection (no state stored)
            db = DatabaseManager("sqlite:///fiscal_documents.db")
            
            stats = db.get_statistics()
            
            result = f"""
üìä **Estat√≠sticas do Banco de Dados**

**Totais:**
- üìÑ Documentos processados: {stats['total_invoices']}
- üõí Itens cadastrados: {stats['total_items']}
- ‚ö†Ô∏è Issues de valida√ß√£o: {stats['total_issues']}
- üí∞ Valor total: R$ {stats['total_value']:,.2f}

**Por Tipo de Documento:**
"""
            
            for doc_type, count in stats['by_type'].items():
                result += f"- {doc_type}: {count} documento(s)\n"
            
            if stats['total_invoices'] == 0:
                result += "\nüí° **Dica:** Fa√ßa upload de XMLs na aba 'Upload' para come√ßar!"
            
            return result
            
        except Exception as e:
            return f"‚ùå Erro ao obter estat√≠sticas: {str(e)}"

    async def _arun(self) -> str:
        """Async version."""
        return self._run()


class AnalyzeValidationIssuesInput(BaseModel):
    """Input schema for analyzing validation issues."""
    
    year: Optional[int] = Field(None, description="Year to filter by (e.g., 2024)")
    month: Optional[int] = Field(None, description="Month to filter by (1-12), requires year")


class ValidationAnalysisTool(BaseTool):
    """Tool for analyzing and reporting on validation issues."""

    name: str = "analyze_validation_issues"
    description: str = """
    Analyze validation issues to identify the most common problems in fiscal documents.
    
    Use this when user asks:
    - "qual o problema de valida√ß√£o mais comum em 2024?"
    - "quais s√£o os problemas de valida√ß√£o mais frequentes?"
    - "qual erro mais ocorre nos documentos?"
    - "problemas de valida√ß√£o do m√™s de janeiro/fevereiro/etc"
    
    You can optionally filter by year and month.
    
    Returns: A detailed analysis of the most common validation issues, their frequency, 
    and severity levels.
    """
    args_schema: type[BaseModel] = AnalyzeValidationIssuesInput

    def _run(self, year: Optional[int] = None, month: Optional[int] = None) -> str:
        """Analyze validation issues."""
        try:
            # Create database connection
            db = DatabaseManager("sqlite:///fiscal_documents.db")
            
            analysis = db.get_validation_issue_analysis(year=year, month=month, limit=10)
            
            if analysis["total_issues"] == 0:
                period_str = f"{year}/{month:02d}" if month else str(year) if year else "all time"
                return f"""
‚ùå **Nenhum problema de valida√ß√£o encontrado**

Per√≠odo analisado: {period_str}

Isso significa que todos os documentos foram validados com sucesso! üéâ
"""
            
            # Build result
            period_str = analysis["period"]
            result = f"""
üìä **An√°lise de Problemas de Valida√ß√£o**

**Per√≠odo:** {period_str}
**Total de Problemas:** {analysis['total_issues']}

**Distribui√ß√£o por Severidade:**
"""
            
            for severity, count in sorted(analysis["by_severity"].items(), key=lambda x: x[1], reverse=True):
                severity_emoji = "üî¥" if severity == "error" else "üü°" if severity == "warning" else "‚ÑπÔ∏è"
                result += f"\n- {severity_emoji} {severity.upper()}: {count} problema(s)"
            
            result += "\n\n**Top Problemas Mais Frequentes:**\n"
            
            for idx, issue in enumerate(analysis["common_issues"], 1):
                result += f"\n{idx}. **[{issue['code']}]** - {issue['count']} ocorr√™ncias"
                result += f"\n   Severidade: {issue['severity']}"
                
                if issue['severity_breakdown']:
                    severity_detail = ", ".join(
                        f"{sev}: {cnt}" 
                        for sev, cnt in sorted(
                            issue['severity_breakdown'].items(),
                            key=lambda x: x[1],
                            reverse=True
                        )
                    )
                    result += f" ({severity_detail})"
                
                if issue['field']:
                    result += f"\n   Campo afetado: {issue['field']}"
                
                if issue['sample_message']:
                    result += f"\n   Exemplo: {issue['sample_message'][:100]}..."
            
            return result
            
        except Exception as e:
            logger.error(f"Error analyzing validation issues: {e}")
            return f"‚ùå Erro ao analisar problemas de valida√ß√£o: {str(e)}"

    async def _arun(self, year: Optional[int] = None, month: Optional[int] = None) -> str:
        """Async version."""
        return self._run(year=year, month=month)


class AnalyzeIssuesByIssuerInput(BaseModel):
    """Input schema for analyzing issues by issuer."""
    
    year: Optional[int] = Field(None, description="Year to filter by (e.g., 2024)")
    month: Optional[int] = Field(None, description="Month to filter by (1-12)")


class IssuerAnalysisTool(BaseTool):
    """Tool for analyzing validation issues grouped by issuer/supplier."""

    name: str = "analyze_issues_by_issuer"
    description: str = """
    Analyze validation issues grouped by issuer (supplier/emitente).
    
    Use this when user asks:
    - "Qual fornecedor tem mais problemas?"
    - "Ranking de fornecedores por taxa de erro"
    - "Quais emitentes t√™m documentos com erros?"
    - "An√°lise de qualidade por fornecedor"
    
    You can optionally filter by year and month.
    
    Returns: Detailed analysis of validation issues per issuer with error rates
    and top problems for each supplier.
    """
    args_schema: type[BaseModel] = AnalyzeIssuesByIssuerInput

    def _run(self, year: Optional[int] = None, month: Optional[int] = None) -> str:
        """Analyze issues by issuer."""
        try:
            db = DatabaseManager("sqlite:///fiscal_documents.db")
            analysis = db.get_validation_issues_by_issuer(year=year, month=month, limit=15)
            
            if not analysis or not analysis.get("issuers"):
                return f"""
‚ùå **Nenhum problema de valida√ß√£o encontrado por emitente**

Per√≠odo: {analysis.get('period', 'all time')}
"""
            
            result = f"""
üìä **An√°lise de Problemas de Valida√ß√£o por Emitente**

**Per√≠odo:** {analysis['period']}
**Total de Emitentes com Problemas:** {analysis['total_issuers']}

"""
            
            for idx, issuer in enumerate(analysis["issuers"], 1):
                result += f"""
{idx}. **{issuer['name']}** (CNPJ: {issuer['cnpj']})
   üìÑ Documentos: {issuer['document_count']}
   üî¥ Erros: {issuer['error_count']}
   üü° Avisos: {issuer['warning_count']}
   üìä Taxa de Erro: {issuer['error_rate']}%
"""
                
                if issuer['top_issues']:
                    result += "   Top Problemas: "
                    result += ", ".join([f"{code}({cnt}x)" for code, cnt in issuer['top_issues']])
                    result += "\n"
            
            return result
            
        except Exception as e:
            logger.error(f"Error analyzing issues by issuer: {e}")
            return f"‚ùå Erro ao analisar problemas por emitente: {str(e)}"

    async def _arun(self, year: Optional[int] = None, month: Optional[int] = None) -> str:
        """Async version."""
        return self._run(year=year, month=month)


class AnalyzeIssuesByOperationInput(BaseModel):
    """Input schema for analyzing issues by operation type."""
    
    year: Optional[int] = Field(None, description="Year to filter by (e.g., 2024)")
    month: Optional[int] = Field(None, description="Month to filter by (1-12)")


class OperationAnalysisTool(BaseTool):
    """Tool for comparing validation issues across operation types."""

    name: str = "analyze_issues_by_operation"
    description: str = """
    Compare validation issues across different operation types (purchase, sale, transfer, return).
    
    Use this when user asks:
    - "Compras t√™m mais erros que vendas?"
    - "Qual tipo de opera√ß√£o tem mais problemas?"
    - "Compara√ß√£o de qualidade entre compras e vendas"
    - "Qual opera√ß√£o fiscal tem mais taxa de erro?"
    
    You can optionally filter by year and month.
    
    Returns: Comparison of validation metrics across all operation types.
    """
    args_schema: type[BaseModel] = AnalyzeIssuesByOperationInput

    def _run(self, year: Optional[int] = None, month: Optional[int] = None) -> str:
        """Analyze issues by operation type."""
        try:
            db = DatabaseManager("sqlite:///fiscal_documents.db")
            analysis = db.get_validation_issues_by_operation(year=year, month=month)
            
            if not analysis.get("by_operation"):
                return f"""
‚ùå **Nenhum documento encontrado para an√°lise**

Per√≠odo: {analysis.get('period', 'all time')}
"""
            
            result = f"""
üìä **Compara√ß√£o de Problemas por Tipo de Opera√ß√£o**

**Per√≠odo:** {analysis['period']}

"""
            
            # Sort by error rate
            sorted_ops = sorted(
                analysis["by_operation"].items(),
                key=lambda x: x[1]["error_rate"],
                reverse=True
            )
            
            for operation, metrics in sorted_ops:
                op_label = {
                    "purchase": "üì• COMPRAS",
                    "sale": "üì§ VENDAS",
                    "transfer": "üîÑ TRANSFER√äNCIAS",
                    "return": "‚Ü©Ô∏è DEVOLU√á√ïES",
                    "unclassified": "‚ùì N√ÉO CLASSIFICADO"
                }.get(operation, f"üìÑ {operation.upper()}")
                
                result += f"""
**{op_label}**
   üìÑ Documentos: {metrics['document_count']}
   üî¥ Erros: {metrics['error_count']}
   üü° Avisos: {metrics['warning_count']}
   üìä Taxa de Erro: {metrics['error_rate']}%
   üìà M√©dia de Problemas/Doc: {metrics['avg_issues_per_doc']}

"""
            
            # Find best and worst
            best_op = min(sorted_ops, key=lambda x: x[1]["error_rate"])
            worst_op = max(sorted_ops, key=lambda x: x[1]["error_rate"])
            
            result += f"""
**üìà Resumo:**
‚úÖ Melhor: {best_op[0].upper()} ({best_op[1]['error_rate']}% de erro)
‚ùå Pior: {worst_op[0].upper()} ({worst_op[1]['error_rate']}% de erro)
"""
            
            return result
            
        except Exception as e:
            logger.error(f"Error analyzing issues by operation: {e}")
            return f"‚ùå Erro ao analisar por tipo de opera√ß√£o: {str(e)}"

    async def _arun(self, year: Optional[int] = None, month: Optional[int] = None) -> str:
        """Async version."""
        return self._run(year=year, month=month)


class DataQualityScoreInput(BaseModel):
    """Input schema for data quality score."""
    
    year: Optional[int] = Field(None, description="Year to analyze (e.g., 2024). If None, uses all data.")


class DataQualityTool(BaseTool):
    """Tool for calculating overall data quality metrics."""

    name: str = "calculate_data_quality"
    description: str = """
    Calculate overall data quality metrics and score (0-100 scale).
    
    Use this when user asks:
    - "Qual √© a qualidade dos nossos documentos?"
    - "Qual % dos documentos tem erros?"
    - "Score de qualidade dos dados"
    - "Dashboard de qualidade"
    - "Como est√° a integridade dos dados?"
    
    Optionally filter by year.
    
    Returns: Quality metrics including completeness, accuracy, consistency,
    and overall quality score.
    """
    args_schema: type[BaseModel] = DataQualityScoreInput

    def _run(self, year: Optional[int] = None) -> str:
        """Calculate data quality score."""
        try:
            db = DatabaseManager("sqlite:///fiscal_documents.db")
            quality = db.calculate_data_quality_score(year=year)
            
            if quality["documents_analyzed"] == 0:
                return f"""
‚ùå **Nenhum documento para an√°lise**

Per√≠odo: {'Year ' + str(year) if year else 'all time'}
"""
            
            # Determine quality level
            score = quality["overall_score"]
            if score >= 90:
                emoji = "üü¢"
                level = "EXCELENTE"
            elif score >= 80:
                emoji = "üü°"
                level = "BOM"
            elif score >= 70:
                emoji = "üü†"
                level = "ACEIT√ÅVEL"
            else:
                emoji = "üî¥"
                level = "CR√çTICO"
            
            result = f"""
üìä **An√°lise de Qualidade de Dados**

**Per√≠odo:** {'Year ' + str(year) if year else 'all time'}

{emoji} **Score Geral: {quality['overall_score']}/100 ({level})**

**Resumo:**
- üìÑ Documentos Analisados: {quality['documents_analyzed']}
- ‚úÖ Documentos Sem Problemas: {quality['documents_clean']}
- üî¥ Documentos com Erros: {quality['documents_with_errors']}
- üü° Documentos com Avisos: {quality['documents_with_warnings']}

**Problemas Detectados:**
- üî¥ Total de Erros: {quality['error_count']} ({quality['error_rate']}%)
- üü° Total de Avisos: {quality['warning_count']} ({quality['warning_rate']}%)
- üìä Total de Problemas: {quality['total_issues']}

**M√©tricas Detalhadas:**
- ‚úÖ Completeness: {quality['metrics']['completeness']}/100
- üéØ Accuracy: {quality['metrics']['accuracy']}/100
- üîó Consistency: {quality['metrics']['consistency']}/100
"""
            
            return result
            
        except Exception as e:
            logger.error(f"Error calculating data quality: {e}")
            return f"‚ùå Erro ao calcular qualidade dos dados: {str(e)}"

    async def _arun(self, year: Optional[int] = None) -> str:
        """Async version."""
        return self._run(year=year)


class RemediationSuggestionsInput(BaseModel):
    """Input schema for remediation suggestions."""
    
    year: Optional[int] = Field(None, description="Year to filter by (e.g., 2024)")
    month: Optional[int] = Field(None, description="Month to filter by (1-12)")
    limit: int = Field(10, description="Max number of suggestions (default 10)")


class RemediationTool(BaseTool):
    """Tool for getting remediation suggestions for validation issues."""

    name: str = "get_remediation_suggestions"
    description: str = """
    Get remediation suggestions for the most common validation issues.
    
    Use this when user asks:
    - "Como corrigir os erros?"
    - "Quais a√ß√µes tomar para resolver os problemas?"
    - "Sugest√µes de remedia√ß√£o"
    - "Como melhorar a qualidade?"
    
    Returns: Prioritized list of issues with recommended actions and steps to fix.
    """
    args_schema: type[BaseModel] = RemediationSuggestionsInput

    def _run(
        self, 
        year: Optional[int] = None, 
        month: Optional[int] = None,
        limit: int = 10
    ) -> str:
        """Get remediation suggestions."""
        try:
            db = DatabaseManager("sqlite:///fiscal_documents.db")
            suggestions = db.get_remediation_suggestions(year=year, month=month, limit=limit)
            
            if suggestions.get("error"):
                return f"‚ùå Erro ao gerar sugest√µes: {suggestions['error']}"
            
            if not suggestions.get("suggestions"):
                return f"""
‚ùå **Nenhuma sugest√£o de remedia√ß√£o dispon√≠vel**

Per√≠odo: {suggestions['period']}
"""
            
            result = f"""
üîß **Sugest√µes de Remedia√ß√£o para Problemas de Valida√ß√£o**

**Per√≠odo:** {suggestions['period']}
**Total de Sugest√µes:** {suggestions['total_suggestions']}

"""
            
            for idx, suggestion in enumerate(suggestions["suggestions"], 1):
                priority_emoji = {
                    "critical": "üî¥",
                    "high": "üü†",
                    "medium": "üü°",
                    "low": "üü¢"
                }.get(suggestion["remediation"]["priority"], "‚ö™")
                
                severity_icon = "‚ùå" if suggestion["severity"] == "error" else "‚ö†Ô∏è"
                
                result += f"""
{idx}. **{suggestion['code']}** {severity_icon}
   üìä Frequ√™ncia: {suggestion['frequency']}x
   üéØ A√ß√£o: {suggestion['remediation']['action']}
   {priority_emoji} Prioridade: {suggestion['remediation']['priority'].upper()}
   üìå Exemplo: {suggestion['sample_message'][:80]}...
   
   **Passos para Corrigir:**
"""
                for step_idx, step in enumerate(suggestion["remediation"]["steps"], 1):
                    result += f"      {step_idx}. {step}\n"
                
                result += "\n"
            
            return result
            
        except Exception as e:
            logger.error(f"Error getting remediation suggestions: {e}")
            return f"‚ùå Erro ao gerar sugest√µes de remedia√ß√£o: {str(e)}"

    async def _arun(
        self, 
        year: Optional[int] = None, 
        month: Optional[int] = None,
        limit: int = 10
    ) -> str:
        """Async version."""
        return self._run(year=year, month=month, limit=limit)


class TrendsAnalysisInput(BaseModel):
    """Input schema for trends analysis."""
    
    months_back: int = Field(12, description="Number of months to analyze (default 12)")


class TrendsTool(BaseTool):
    """Tool for analyzing validation issue trends over time."""

    name: str = "analyze_validation_trends"
    description: str = """
    Analyze trends in validation issues over time (monthly aggregation).
    
    Use this when user asks:
    - "Os erros est√£o aumentando ou diminuindo?"
    - "Qual √© a tend√™ncia de qualidade?"
    - "An√°lise de tend√™ncias de problemas"
    - "Evolu√ß√£o da qualidade dos documentos"
    - "Problemas est√£o melhorando?"
    
    You can optionally specify number of months to analyze (default 12).
    
    Returns: Monthly aggregation of errors/warnings with trend direction.
    """
    args_schema: type[BaseModel] = TrendsAnalysisInput

    def _run(self, months_back: int = 12) -> str:
        """Analyze trends."""
        try:
            db = DatabaseManager("sqlite:///fiscal_documents.db")
            trends = db.analyze_trends(months_back=months_back)
            
            if trends.get("error"):
                return f"‚ùå Erro ao analisar tend√™ncias: {trends['error']}"
            
            if trends["data_points"] == 0:
                return f"""
‚ùå **Dados insuficientes para an√°lise de tend√™ncias**

Meses analisados: {months_back}
"""
            
            result = f"""
üìà **An√°lise de Tend√™ncias de Problemas de Valida√ß√£o**

**Per√≠odo:** {trends['first_period']} at√© {trends['last_period']}
**Meses Analisados:** {trends['months_analyzed']}
**Pontos de Dados:** {trends['data_points']}

{trends['trend_direction']}

üìä **Taxa M√©dia de Erro:** {trends['average_error_rate']}%

**Dados Mensais:**

"""
            
            for month_data in trends["monthly_data"]:
                # Visual bar representation
                error_bar = "‚ñà" * int(month_data["error_rate"] / 2)
                
                result += f"""
**{month_data['period']}**
   üìÑ Documentos: {month_data['documents']}
   üî¥ Erros: {month_data['errors']}
   üü° Avisos: {month_data['warnings']}
   üìä Taxa de Erro: {month_data['error_rate']}% {error_bar}
"""
            
            # Analysis
            if trends["data_points"] >= 2:
                first = trends["monthly_data"][0]
                last = trends["monthly_data"][-1]
                
                change = last["error_rate"] - first["error_rate"]
                pct_change = (change / first["error_rate"] * 100) if first["error_rate"] > 0 else 0
                
                result += f"""
**üìä An√°lise:**
   Primeira medi√ß√£o: {first['period']} ({first['error_rate']}%)
   √öltima medi√ß√£o: {last['period']} ({last['error_rate']}%)
   Mudan√ßa: {change:+.2f}pp ({pct_change:+.1f}%)
"""
                
                if change < -0.5:
                    result += "   ‚úÖ **POSITIVO**: Qualidade est√° melhorando!\n"
                elif change > 0.5:
                    result += "   ‚ö†Ô∏è **NEGATIVO**: Qualidade est√° piorando. Investigar!\n"
                else:
                    result += "   ‚û°Ô∏è **EST√ÅVEL**: Qualidade mant√©m-se consistente.\n"
            
            return result
            
        except Exception as e:
            logger.error(f"Error analyzing trends: {e}")
            return f"‚ùå Erro ao analisar tend√™ncias: {str(e)}"

    async def _arun(self, months_back: int = 12) -> str:
        """Async version."""
        return self._run(months_back=months_back)


# Tool instances
parse_xml_tool = ParseXMLTool()
validate_invoice_tool = ValidateInvoiceTool()
fiscal_knowledge_tool = FiscalKnowledgeTool()
database_search_tool = DatabaseSearchTool()
database_stats_tool = DatabaseStatsTool()
validation_analysis_tool = ValidationAnalysisTool()
issuer_analysis_tool = IssuerAnalysisTool()
operation_analysis_tool = OperationAnalysisTool()
data_quality_tool = DataQualityTool()
remediation_tool = RemediationTool()
trends_tool = TrendsTool()

# Import business tools
from src.agent.business_tools import ALL_BUSINESS_TOOLS
from src.agent.archiver_tools import ALL_ARCHIVER_TOOLS

# Import report generation tool
from .report_tool import FiscalReportExportTool
fiscal_report_export_tool = FiscalReportExportTool()

# All tools list
ALL_TOOLS = [
    parse_xml_tool,
    validate_invoice_tool,
    fiscal_knowledge_tool,
    database_search_tool,
    database_stats_tool,
    validation_analysis_tool,           # New: analyze common validation issues
    issuer_analysis_tool,               # New: SPRINT 1 - analyze by issuer
    operation_analysis_tool,            # New: SPRINT 1 - compare by operation type
    data_quality_tool,                  # New: SPRINT 1 - overall quality metrics
    remediation_tool,                   # New: SPRINT 1 - remediation suggestions
    trends_tool,                        # New: SPRINT 1 - trend analysis
    fiscal_report_export_tool,          # CSV/XLSX file export for download
    *ALL_BUSINESS_TOOLS,                # Includes 'generate_report' for interactive charts
    *ALL_ARCHIVER_TOOLS,
]



